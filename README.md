# LLaMA

Welcome to **LLaMA**, my custom library for training and fine-tuning the LLaMA model.

## Features

Currently, this library supports:

1. Flash Attention
2. KV Cache
3. Triton RMSNorm
4. Flash RoPE

### Coming Soon

I'm actively working on integrating the following features:

1. **Tensor Parallelism**: 
2. **Pipeline Parallelism**
3. **Training Benchmark**
